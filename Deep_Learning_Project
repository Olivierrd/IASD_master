# -*- coding: utf-8 -*-
"""Projet_Deep_Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11akM-4uExqbk_dkHwL9hI1KwJTjlEPcw

IMPORTANT : le prof s'interesse à deux métrics : (best ever value) val_policy_acc : 0.40 et val_loss : 2

#Libraries
"""

!pip install pybind11
import pybind11
print(pybind11.get_include())
!pip install torch
import tensorflow as tf
import torch    
import tensorflow.keras as keras
from tensorflow.keras import layers 
from keras.models import Sequential
from keras.layers.core import Dense, Activation
from keras.optimizers import SGD,Adam,Adamax,nadam,RMSprop
import numpy as np
import matplotlib.pyplot as plt
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D
from keras import regularizers
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/"
!ls

!bash compile.sh

#Original goilois.py file
!python /content/drive/My\ Drive/Dauphine/Deep_learning_CT/DeepLearningProject/golois.py

"""##useless"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow
print(tensorflow.__version__)

import golois

import pandas as pd
df = pd.read_csv("games.data")

df=df.rename(columns={"500000": "Name"})

df = df.Name.str.split(expand=True)

print(df.shape)
print(df)

with pd.option_context('display.max_rows', None, 'display.max_columns', None): 
  print(df.iloc[3])

input_data = np.load ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/input_data.npy')
policy = np.load ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/policy.npy')
value = np.load ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/value.npy')
end = np.load ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/end.npy')

"""##Start"""

import golois
planes = 8
moves = 361
dynamicBatch = True
if dynamicBatch:
  import sys 
  sys.path.append('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/golois.cpp')
  #import golois.cpp
  N = 700000
  input_data = np.random.randint(2, size=(N, 19, 19, planes))
  input_data = input_data.astype ('float32')
      
  policy = np.random.randint(moves, size=(N,))
  policy = keras.utils.to_categorical (policy)
      
  value = np.random.randint(2, size=(N,))
  value = value.astype ('float32')
      
  end = np.random.randint(2, size=(N, 19, 19, 2))
  end = end.astype ('float32')

golois.getBatch(input_data, policy, value,end)

"""#**Common functions**"""

def create_test_train_db(db,size) :
  shape_ = db.shape[0]
  train = db[:int(shape_*size)]
  test = db[int(shape_*size):]
  return train,test

def load_data(input_data = np.load ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/input_data.npy'),
              policy = np.load('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/policy.npy'),
              value = np.load('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/value.npy'),
              end = np.load('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/end.npy')) : 
  input_data_train, input_data_test = create_test_train_db(input_data, 0.99)
  policy_train, policy_test = create_test_train_db(policy, 0.99)
  value_train, value_test = create_test_train_db(value, 0.99)
  end_train, end_test = create_test_train_db(end, 0.99)
  return input_data_train, policy_train, value_train, input_data_test, policy_test, value_test

input_data_train, policy_train, value_train, input_data_test, policy_test, value_test  = load_data(input_data, policy, value,end)
#input_data_train, policy_train, value_train, input_data_test, policy_test, value_test  = load_data()

input_data_train[1][1]

"""# **Section Olivier**"""

def define_model(model_number = 1, epochs = 10, input_data_train = input_data_train , policy_train = policy_train,
                 value_train = value_train, input_data_test = input_data_test,
                 policy_test = policy_test, value_test = value_test) :
  input = keras.Input(shape=(19, 19, 8), name='board')
  if model_number == 1:
    policy_head, value_head = model_TC(input)

  elif model_number==2 : 
    policy_head, value_head = model_2(input)

  elif model_number == 3 :
    policy_head, value_head = model_3_dynamic(input)

  model = keras.Model(inputs=input, outputs=[policy_head, value_head])

  model.summary ()

  model.compile(optimizer=keras.optimizers.SGD(lr=0.1),
                loss={'value': 'mse', 'policy': 'categorical_crossentropy'},
                metrics=['accuracy'])
  
  history = model.fit(input_data_train, {'policy': policy_train, 'value': value_train},
            epochs=epochs, batch_size=128, validation_split=0.1)
  model.evaluate(input_data_test, {'policy': policy_test, 'value': value_test})

  model_save_name = 'test.h5'
  #path = F"/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/{model_save_name}" 
  #torch.save(model.save(path), path)
  return history,model

"""## **TC's model**"""

import tensorflow as tf
import tensorflow.keras as keras
import numpy as np
from tensorflow.keras import layers 
import torch

def model_TC(input):
  planes = 8
  moves = 361
  x = layers.Conv2D(32, 3, activation='relu', padding='same')(input)
  x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
  policy_head = layers.Conv2D(1, 3, activation='relu', padding='same')(x)
  policy_head = layers.Flatten()(policy_head)
  policy_head = layers.Dense(moves, activation='softmax', name='policy')(policy_head)
  value_head = layers.Flatten()(x)
  value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)

  return policy_head, value_head

TC = define_model(1,30)
history1 = TC[0]

"""##**Olivier's Models**"""

def model_2(input) :
  x = layers.Conv2D(32, 4, activation='relu', padding='same')(input)
  ident = x
  x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
  x = layers.add([ident,x])
  ident = x
  x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
  x = layers.add([ident,x])
  ident = x
  x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
  x = layers.add([ident,x])

  policy_head = layers.Conv2D(6, 4, activation='relu', padding='same')(x) 
  policy_head = layers.Flatten()(policy_head)
  policy_head = layers.Dense(361, activation='softmax', name='policy')(policy_head)

  value_head = layers.Flatten()(x)
  value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)
  return policy_head,value_head

test2 = define_model(2,30)
history2 = test2[0]

# app bcp plus rapide 12 suffit et acc à 20%

def model_3_dynamic(input) :
  x = layers.Conv2D(32, 3, activation='relu', padding='same')(input)
  ident = x
  x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
  x = layers.add([ident,x])

  policy_head = layers.Conv2D(6, 3, activation='relu', padding='same')(x)  
  policy_head = layers.Flatten()(policy_head)
  policy_head = layers.Dense(361, activation='softmax', name='policy')(policy_head)

  value_head = layers.Flatten()(x)
  value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)
  return policy_head,value_head

test3 = define_model(3,20)
history3 = test3[0]

"""##**Plot : model comparaison**"""

#TRAIN loss policy + loss
loss_train_1 = history1.history['loss']
loss_policy_train_1 = history1.history['policy_loss']
loss_train_2 = history2.history['loss']
loss_policy_train_2 = history2.history['policy_loss']
loss_train_3 = history3.history['loss']
loss_policy_train_3 = history3.history['policy_loss']

epochs = np.arange(len(loss_train_1))+1
plt.plot(epochs,loss_train_1, label='loss_train_1')
plt.plot(epochs,loss_policy_train_1, label='loss_policy_train_1')
plt.plot(epochs,loss_train_2, label='loss_train_2')
plt.plot(epochs,loss_policy_train_2, label='loss_policy_train_2')
plt.plot(epochs,loss_train_3, label='loss_train_3')
plt.plot(epochs,loss_policy_train_3, label='loss_policy_train_3')

plt.legend()
plt.title("evolution de la courbe loss TRAIN")
plt.show()


#TRAIN loss value

value_loss_train_1 = history1.history['value_loss']
value_loss_train_2 = history2.history['value_loss']
value_loss_train_3 = history3.history['value_loss']

plt.plot(epochs,value_loss_train_1, label='value_loss_train_1')
plt.plot(epochs,value_loss_train_2, label='value_loss_train_2')
plt.plot(epochs,value_loss_train_3, label='value_loss_train_3')

plt.legend()
plt.title("evolution de la courbe value_loss TRAIN")
plt.show()

#TRAIN acc

acc_policy_3 = history3.history['policy_acc']
acc_value_3 = history3.history['value_acc']
acc_policy_2 = history2.history['policy_acc']
acc_value_2 = history2.history['value_acc']
acc_policy_1= history1.history['policy_acc']
acc_value_1= history1.history['value_acc']

plt.plot(epochs,acc_policy_2, label='acc_policy_2')
plt.plot(epochs,acc_value_2, label='acc_value_2')
plt.plot(epochs,acc_policy_3, label='acc_policy_3')
plt.plot(epochs,acc_value_3, label='acc_value_3')
plt.plot(epochs,acc_policy_1, label='acc_policy_1')
plt.plot(epochs,acc_value_1, label='acc_value_1')

plt.legend()
plt.title("evolution de la courbe acc TRAIN ")
plt.show()

#VALID loss policy+ loss
loss_valid_1 = history1.history['val_loss']
loss_policy_valid_1 = history1.history['val_policy_loss']
loss_valid_2 = history2.history['val_loss']
loss_policy_valid_2 = history2.history['val_policy_loss']
loss_valid_3 = history3.history['val_loss']
loss_policy_valid_3 = history3.history['val_policy_loss']

plt.plot(epochs,loss_valid_1, label='loss_valid_1')
plt.plot(epochs,loss_policy_valid_1, label='loss_policy_valid_1')
plt.plot(epochs,loss_valid_2, label='loss_valid_2')
plt.plot(epochs,loss_policy_valid_2, label='loss_policy_valid_2')
plt.plot(epochs,loss_valid_3, label='loss_valid_3')
plt.plot(epochs,loss_policy_valid_3, label='loss_policy_valid_3')

plt.legend()
plt.title("evolution de la courbe loss TRAIN")
plt.show()


#VALID loss value

value_loss_valid_1 = history1.history['val_value_loss']
value_loss_valid_2 = history2.history['val_value_loss']
value_loss_valid_3 = history3.history['val_value_loss']

plt.plot(epochs,value_loss_valid_1, label='value_loss_valid_1')
plt.plot(epochs,value_loss_valid_2, label='value_loss_valid_2')
plt.plot(epochs,value_loss_valid_3, label='value_loss_valid_3')

plt.legend()
plt.title("evolution de la courbe val_value_loss TRAIN")
plt.show()

#VALID acc
acc_policy_val_3 = history3.history['val_policy_acc']
acc_value_val_3 = history3.history['val_value_acc']
acc_policy_val_2 = history2.history['val_policy_acc']
acc_value_val_2 = history2.history['val_value_acc']
acc_policy_val_1= history1.history['val_policy_acc']
acc_value_val_1= history1.history['val_value_acc']

plt.plot(epochs,acc_policy_val_2, label='acc_policy_val_2')
plt.plot(epochs,acc_value_val_2, label='acc_value_val_2')
plt.plot(epochs,acc_policy_val_3, label='acc_policy_val_3')
plt.plot(epochs,acc_value_val_3, label='acc_value_val_3')
plt.plot(epochs,acc_policy_val_1, label='acc_policy_val_1')
plt.plot(epochs,acc_value_val_1, label='acc_value_val_1')

plt.legend()
plt.title("evolution de la courbe acc VALIDATION ")
plt.show()

"""## **Model_schema**"""

keras.utils.plot_model(test2[1], 'my_first_model_with_shape_info.png', show_shapes=True)

"""### Model_plot_TC"""

keras.utils.plot_model(TC[1], 'my_first_model_with_shape_info.png', show_shapes=True)

"""### Model_plot_2"""

keras.utils.plot_model(test3[1], 'my_first_model_with_shape_info.png', show_shapes=True)

"""# Test Algo Maxime"""

def maxime_model(model_number = 1, epochs = 10) :
  planes = 8
  moves = 361
  dynamicBatch = False
  if dynamicBatch:
      import sys 
      sys.path.append('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/golois.cpp')
      import golois.cpp
      N = 100000
      input_data = np.random.randint(2, size=(N, 19, 19, planes))
      input_data = input_data.astype ('float32')
      
      policy = np.random.randint(moves, size=(N,))
      policy = keras.utils.to_categorical (policy)
      
      value = np.random.randint(2, size=(N,))
      value = value.astype ('float32')
      
      end = np.random.randint(2, size=(N, 19, 19, 2))
      end = end.astype ('float32')

      golois.getBatch (input_data, policy, value, end)
  else:
      input_data = np.load ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/input_data.npy')
      policy = np.load ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/policy.npy')
      value = np.load ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/value.npy')
      end = np.load ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/end.npy')

  if model_number == 1:
    input = keras.Input(shape=(19, 19, planes), name='board')
    x = layers.Conv2D(32, 3, activation='relu', padding='same')(input)
    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)


    policy_head = layers.Conv2D(1, 3, activation='relu', padding='same')(x)
    policy_head = layers.Flatten()(policy_head)
    policy_head = layers.Dense(moves, activation='softmax', name='policy')(policy_head)

    value_head = layers.Flatten()(x)
    value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)

  elif model_number==2 : 
    input = keras.Input(shape=(19, 19, planes), name='board')
    x = layers.LeakyReLU()(input)
    x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
    ident=x
    x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
    x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
    x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
    x = layers.BatchNormalization(axis=1)(x)
    x = layers.Dense(32, activation = "relu")(x)
    x=layers.add([ident,x])
    ident1=x
    x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
    x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
    x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
    x=layers.add([ident1,x])
    ident2=x
    x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
    x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
    x = layers.Conv2D(32, 4, activation='relu', padding='same')(x)
    x = layers.BatchNormalization(axis=1)(x)
    x = layers.Dense(32, activation = "relu")(x)
    x=layers.add([ident2,x])

    policy_head = layers.Conv2D(1, 8, activation='relu', padding='same')(x)
    policy_head = layers.BatchNormalization(axis=1)(policy_head)
    policy_head=layers.MaxPooling2D(pool_size=(2, 2),padding='same')(policy_head)
    policy_head=layers.Dropout(0.3)(policy_head)
    policy_head = layers.Flatten()(policy_head)
    policy_head = layers.Dense(moves, activation='softmax', name='policy')(policy_head)

    value_head = layers.Conv2D(32, 8, activation='relu', padding='same')(x)
    value_head = layers.BatchNormalization(axis=1)(value_head)
    value_head = layers.Dense(32, activation = "relu")(value_head)
    value_head = layers.Flatten()(value_head)
    value_head = layers.Dense(16, activation='relu')(value_head)
    value_head = layers.LeakyReLU()(value_head)
    value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)

  model = keras.Model(inputs=input, outputs=[policy_head, value_head])

  model.summary ()

  model.compile(optimizer=keras.optimizers.SGD(lr=0.1),
                loss={'value': 'mse', 'policy': 'categorical_crossentropy'},
                metrics=['accuracy'])

  history1 = model.fit(input_data, {'policy': policy, 'value': value},
            epochs=epochs, batch_size=128, validation_split=0.1)


  model_save_name = 'test.h5'
  path = F"/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/{model_save_name}" 
  torch.save(model.save(path), path)
  # model.save ('test.h5')
  return history1,model

testm2 = maxime_model(2,20)
history2 = testm2[0]
loss_value_train_2 = history2.history['value_loss']
loss_policy_train_2 = history2.history['policy_loss']

test1 = maxime_model(1,20)
history1 = test1[0]
loss_value_train = history1.history['value_loss']
loss_policy_train = history1.history['policy_loss']

epochs = np.arange(len(loss_value_train))+1
plt.plot(epochs,loss_policy_train, label='loss_policy_train')
plt.plot(epochs,loss_policy_train_2, label='loss_policy_train_2')
plt.legend()
plt.title("evolution de la courbe loss policy sur l'apprentissage")
plt.show()

plt.plot(epochs,loss_value_train, label='loss_value_train')
plt.plot(epochs,loss_value_train_2, label='loss_value_train_2')
plt.legend()
plt.title("evolution de la courbe loss value sur l'apprentissage")
plt.show()

keras.utils.plot_model(testm2[1], 'my_first_model_with_shape_info.png', show_shapes=True)

acc_policy_val_2 = history2.history['val_policy_acc']
acc_value_val_2 = history2.history['val_value_acc']

acc_policy_val_1= history1.history['val_policy_acc']
acc_value_val_1= history1.history['val_value_acc']

plt.plot(epochs,acc_policy_val_2, label='acc_policy_val_2')
plt.plot(epochs,acc_policy_val_1, label='acc_policy_val_1')
plt.legend()
plt.title("evolution de la courbe accuracy policy")
plt.show()

plt.plot(epochs,acc_value_val_2, label='acc_value_val_2')
plt.plot(epochs,acc_value_val_1, label='acc_value_val_1')
plt.legend()
plt.title("evolution de la courbe accuracy value")
plt.show()

"""# Test Max"""

input_data = np.load ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/input_data.npy')
policy = np.load ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/policy.npy')
value = np.load ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/value.npy')
end = np.load ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/end.npy')

planes = 8
moves = 361
epochs = 30

input = keras.Input(shape=(19, 19, planes), name='board')
x = layers.Conv2D(32, 3, activation='relu', padding='same')(input)
x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)

policy_head = layers.Conv2D(1, 3, activation='relu', padding='same')(x)
policy_head = layers.Flatten()(policy_head)
policy_head = layers.Dense(moves, activation='softmax', name='policy')(policy_head)

value_head = layers.Flatten()(x)
value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)

model = keras.Model(inputs=input, outputs=[policy_head, value_head])
model.summary ()
model.compile(optimizer=keras.optimizers.SGD(lr=0.1),
                loss={'value': 'mse', 'policy': 'categorical_crossentropy'},
                metrics=['accuracy'])

history= model.fit(input_data, {'policy': policy, 'value': value},
            epochs=epochs, batch_size=128, validation_split=0.2)

input = keras.Input(shape=(19, 19, planes), name='board')
x = layers.LeakyReLU()(input)
x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
ident=x
x = layers.BatchNormalization(axis=1)(x)
x = layers.Dense(32, activation = "relu")(x)
x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
x = layers.BatchNormalization(axis=1)(x)
x = layers.Dense(32, activation = "relu")(x)
x = layers.add([ident,x])



policy_head = layers.Conv2D(1, 3, activation='relu', padding='same')(x)
policy_head = layers.Flatten()(policy_head)
policy_head = layers.Dense(moves, activation='softmax', name='policy')(policy_head)

value_head = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
value_head = layers.BatchNormalization(axis=1)(value_head)
value_head = layers.Dense(32, activation = "relu")(value_head)
value_head = layers.Flatten()(value_head)
value_head = layers.LeakyReLU()(value_head)
value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)

model = keras.Model(inputs=input, outputs=[policy_head, value_head])
model.summary ()

model.compile(optimizer=keras.optimizers.SGD(lr=0.1),
                loss={'value': 'mse', 'policy': 'categorical_crossentropy'},
                metrics=['accuracy'])

history1= model.fit(input_data, {'policy': policy, 'value': value},
            epochs=35, batch_size=128, validation_split=0.2)

#model_save_name = 'model_MT/OR_v1.h5'
#path = F"/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/{model_save_name}" 
#torch.save(model.save(path), path)
model.save ('/content/drive/My Drive/Dauphine/Deep_learning_CT/DeepLearningProject/model_MT_OR_v2.h5')

keras.utils.plot_model(model, 'model_MT_OR_v1.png', show_shapes=True)

loss_value_train_2 = history1.history['value_loss']
loss_policy_train_2 = history1.history['policy_loss']

loss_value_train = history.history['value_loss']
loss_policy_train = history.history['policy_loss']

epochs = np.arange(len(loss_value_train))+1
plt.plot(epochs,loss_policy_train, label='loss_policy_train')
plt.plot(epochs,loss_policy_train_2, label='loss_policy_train_2')
plt.legend()
plt.title("evolution de la courbe loss policy sur l'apprentissage")
plt.show()

plt.plot(epochs,loss_value_train, label='loss_value_train')
plt.plot(epochs,loss_value_train_2, label='loss_value_train_2')
plt.legend()
plt.title("evolution de la courbe loss value sur l'apprentissage")
plt.show()

acc_policy_val_2 = history1.history['val_policy_acc']
acc_value_val_2 = history1.history['val_value_acc']

acc_policy_val_1= history.history['val_policy_acc']
acc_value_val_1= history.history['val_value_acc']

plt.plot(epochs,acc_policy_val_2, label='acc_policy_val_2')
plt.plot(epochs,acc_policy_val_1, label='acc_policy_val_1')
plt.legend()
plt.title("evolution de la courbe accuracy policy")
plt.show()

plt.plot(epochs,acc_value_val_2, label='acc_value_val_2')
plt.plot(epochs,acc_value_val_1, label='acc_value_val_1')
plt.legend()
plt.title("evolution de la courbe accuracy value")
plt.show()

input = keras.Input(shape=(19, 19, planes), name='board')
x = layers.Conv2D(8, 3, activation='relu', padding='same')(input)
ident=x
x = layers.Conv2D(8, 3, activation='relu', padding='same')(x)
x = layers.Conv2D(8, 3, activation='relu', padding='same')(x)
x = layers.Conv2D(8, 3, activation='relu', padding='same')(x)
x=layers.add([ident,x])

x = layers.Conv2D(16, 3, activation='relu', padding='same')(x)
ident1=x
x = layers.Conv2D(16, 3, activation='relu', padding='same')(x)
x = layers.Conv2D(16, 3, activation='relu', padding='same')(x)
x=layers.add([ident1,x])

x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
ident2=x
x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
x=layers.add([ident2,x])

policy_head = layers.Conv2D(1, 3, activation='relu', padding='same')(x)
policy_head = layers.Flatten()(policy_head)
policy_head = layers.Dense(moves, activation='softmax', name='policy')(policy_head)

value_head = layers.Flatten()(x)
value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)

model = keras.Model(inputs=input, outputs=[policy_head, value_head])
model.summary ()

model.compile(optimizer=keras.optimizers.SGD(lr=0.1),
                loss={'value': 'mse', 'policy': 'categorical_crossentropy'},
                metrics=['accuracy'])

history1= model.fit(input_data, {'policy': policy, 'value': value},
            epochs=50, batch_size=128, validation_split=0.2)

