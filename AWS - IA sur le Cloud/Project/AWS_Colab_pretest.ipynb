{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of AWS_Post.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW-uyvYyucjX",
        "colab_type": "text"
      },
      "source": [
        "#Make a POST request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAEaCPAXiHEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e51ef27c-4b86-45e2-bef2-ed4cebce51e0"
      },
      "source": [
        "import requests\n",
        "url = \"https://29nr10lpth.execute-api.us-east-1.amazonaws.com/skanner_predict_picture\"\n",
        "#url = \"http://e7a41f244533.ngrok.io\"\n",
        "\n",
        "#arr = imread('aamrmacbsylkbahdhvcfmeqvgyjopc.jpg')\n",
        "arr = imread(path_image)\n",
        "data = {'media': arr.tolist()}\n",
        "response = requests.post(url, json=data)\n",
        "response"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [500]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9DY-GDRuh5W",
        "colab_type": "text"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5BAqe1fF1Ys",
        "colab_type": "text"
      },
      "source": [
        "##Mnist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvHTmGks9sq-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ef64da7-d985-4319-8ef6-1476dddf3cd5"
      },
      "source": [
        "import time\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def resize100(img):\n",
        "    return resize(img, (224,224), preserve_range=True, mode='reflect', anti_aliasing=True)\n",
        "\n",
        "image = np.expand_dims(resize100(imread(path_image)),0)\n",
        "image.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-fG4k6fF5xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.Dense(128,activation='relu'),\n",
        "  tf.keras.layers.Dense(2, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=['accuracy'],\n",
        "  )\n",
        "\n",
        "  return model\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "tf.enable_v2_behavior()\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(128)\n",
        "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "ds_test = ds_test.batch(128)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=6,\n",
        "    validation_data=ds_test,\n",
        ")\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "\n",
        "\n",
        "model.save(\"model\")\n",
        "model = tf.keras.models.load_model('model')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "open(\"model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "\n",
        "print(\"Saved model to disk\")\n",
        "# Create a new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Restore the weights\n",
        "model.load_weights(\"model.h5\")\n",
        "\n",
        "# Evaluate the model from model.h5\n",
        "arr = imread('aamrmacbsylkbahdhvcfmeqvgyjopc.jpg')\n",
        "print(arr.shape)\n",
        "image = resize100(imread('/content/aamrmacbsylkbahdhvcfmeqvgyjopc.jpg'))\n",
        "print(image.shape)\n",
        "image = normalize_img(image, 1)[0]\n",
        "print(image.shape)\n",
        "image =tf.image.rgb_to_grayscale(image, name=None)\n",
        "print(image.shape)\n",
        "t = model.predict(np.expand_dims(normalize_img(image,0)[0],0))\n",
        "print(np.argmax(t))\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CHYnyQfyJW3",
        "colab_type": "text"
      },
      "source": [
        "##Our Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlP4M2oUu78a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "def create_model():\n",
        "    IMAGE_SIZE= [224,224]\n",
        "    pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
        "    pretrained_model.trainable = False \n",
        "\n",
        "\n",
        "    output = tf.keras.layers.Flatten()(pretrained_model.output)\n",
        "    output = tf.keras.layers.Dense(units = 256, activation='relu',)(output) \n",
        "    output = tf.keras.layers.BatchNormalization()(output)\n",
        "    output = tf.keras.layers.Dropout(0.9)(output)\n",
        "    output = tf.keras.layers.Dense(2 ,activation='softmax')(output)\n",
        "\n",
        "    model_vgg16 = tf.keras.Model(pretrained_model.input, output)\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
        "    #model.compile(optimizer=opt, loss= tf.keras.losses.BinaryCrossentropy() , metrics=['accuracy'])\n",
        "    model_vgg16.compile(#loss='sparse_categorical_crossentropy',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy', tf.keras.metrics.AUC()])\n",
        "                  #metrics=['accuracy', tf.keras.metrics.AUC()])\n",
        "\n",
        "    return model_vgg16\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "tf.enable_v2_behavior()\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(128)\n",
        "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "ds_test = ds_test.batch(128)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=6,\n",
        "    validation_data=ds_test,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU5wGWMOt6zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model('gdrive/My Drive/Thesis/models/model_aws.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg2-ITFtHHkW",
        "colab_type": "text"
      },
      "source": [
        "###Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPHkq23P_q9q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "aeeebf69-4780-4d08-a512-16afbcc6e18d"
      },
      "source": [
        "from PIL import Image\n",
        "for i in range(1,10):\n",
        "  arr = imread(f\"gdrive/My Drive/Thesis/models/melanoma_{i}.jpg\") / 255\n",
        "\n",
        "  print(arr.shape)\n",
        "  image = tf.image.resize(arr,[224,224])\n",
        "  print(image.shape)\n",
        "  t = model.predict(np.expand_dims(image,0))\n",
        "  print(np.argmax(t))\n",
        "  print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1705, 2450, 3)\n",
            "(224, 224, 3)\n",
            "0\n",
            "[[0.9948632  0.00513678]]\n",
            "(1705, 2450, 3)\n",
            "(224, 224, 3)\n",
            "0\n",
            "[[0.9948632  0.00513678]]\n",
            "(1705, 2450, 3)\n",
            "(224, 224, 3)\n",
            "0\n",
            "[[0.9948632  0.00513678]]\n",
            "(1705, 2450, 3)\n",
            "(224, 224, 3)\n",
            "0\n",
            "[[0.9948632  0.00513678]]\n",
            "(1705, 2450, 3)\n",
            "(224, 224, 3)\n",
            "0\n",
            "[[0.9948632  0.00513678]]\n",
            "(1705, 2450, 3)\n",
            "(224, 224, 3)\n",
            "0\n",
            "[[0.9948632  0.00513678]]\n",
            "(1705, 2450, 3)\n",
            "(224, 224, 3)\n",
            "0\n",
            "[[0.9948632  0.00513678]]\n",
            "(1705, 2450, 3)\n",
            "(224, 224, 3)\n",
            "0\n",
            "[[0.9948632  0.00513678]]\n",
            "(1705, 2450, 3)\n",
            "(224, 224, 3)\n",
            "0\n",
            "[[0.9948632  0.00513678]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV9iQt-OTFQM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ef147b14-547c-44c3-b8dd-ac57122cc6d9"
      },
      "source": [
        "import tensorflow.compat.v2 as tf\n",
        "import numpy as np\n",
        "model1 = tf.keras.models.load_model('model_aws.h5')\n",
        "model1.save_weights(\"weights_only.h5\")\n",
        "json_config = model1.to_json()\n",
        "with open('model_config.json', 'w') as json_file:\n",
        "    json_file.write(json_config)\n",
        "\n",
        "##TF 1.14\n",
        "with open('model_config.json') as json_file:\n",
        "    json_config = json_file.read()\n",
        "model2 = tf.keras.models.model_from_json(json_config)\n",
        "model2.load_weights('weights_only.h5')\n",
        "\n",
        "\n",
        "t = [\"/content/benign_3.jpg\", \"/content/benign_5.jpg\", \"/content/melanoma_7.jpg\", \"/content/melanoma_4.jpg\", \"/content/melanoma.jpeg\"]\n",
        "model3 = tf.keras.models.load_model('/content/oversampling.h5')\n",
        "\n",
        "for i in t : \n",
        "  arr = tf.keras.preprocessing.image.load_img(i)\n",
        "  arr = tf.keras.preprocessing.image.img_to_array(arr) / 255\n",
        "  image = tf.image.resize(arr,[224,224])\n",
        "  t = model2.predict(np.expand_dims(image,0))\n",
        "  t1 = model1.predict(np.expand_dims(image,0))\n",
        "  t3 = model3.predict(np.expand_dims(image,0))\n",
        "\n",
        "  print(i, np.argmax(t), t[0][np.argmax(t)])\n",
        "  print(i, np.argmax(t1), t[0][np.argmax(t1)])\n",
        "  print(i, np.argmax(t3), t[0][np.argmax(t3)])\n",
        "\n",
        "  print()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/benign_3.jpg 0 0.99999714\n",
            "/content/benign_3.jpg 0 0.99999714\n",
            "/content/benign_3.jpg 1 2.902074e-06\n",
            "\n",
            "/content/benign_5.jpg 0 0.9998882\n",
            "/content/benign_5.jpg 0 0.9998882\n",
            "/content/benign_5.jpg 1 0.00011174734\n",
            "\n",
            "/content/melanoma_7.jpg 0 0.99998856\n",
            "/content/melanoma_7.jpg 0 0.99998856\n",
            "/content/melanoma_7.jpg 1 1.1412838e-05\n",
            "\n",
            "/content/melanoma_4.jpg 0 0.999673\n",
            "/content/melanoma_4.jpg 0 0.999673\n",
            "/content/melanoma_4.jpg 1 0.0003270189\n",
            "\n",
            "/content/melanoma.jpeg 0 1.0\n",
            "/content/melanoma.jpeg 0 1.0\n",
            "/content/melanoma.jpeg 0 1.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOJKlq-kuuar",
        "colab_type": "text"
      },
      "source": [
        "#Take a photo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCg8CuBnuiEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSLDniYguixr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYEWlWVbum5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "image=mpimg.imread('photo.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}